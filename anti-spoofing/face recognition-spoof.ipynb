{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The face encoding model is a ResNet.\n",
    "\n",
    "To improve recognition accuracy:\n",
    "\n",
    "1. add jitters to the face encoding, this tells dlib to randomly distort your image, take encodings of all and return the averaged encodings. this will make the algorithm slow though.\n",
    "2. add unsampling i.e zoomingg to the original image, this will help detect the smaller faces in the image, at the cost of slow run time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import face_utils\n",
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import openface\n",
    "import face_recognition\n",
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import keras\n",
    "from random import shuffle\n",
    "from keras.layers import Dense, Dropout, Activation, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "\n",
    "IMG_SIZE=500\n",
    "\n",
    "def get_face_embeddings_from_image(image, convert_to_rgb=False):\n",
    "    \"\"\"\n",
    "    Take a raw image and run both the face detection and face embedding model on it\n",
    "    \"\"\"\n",
    "    # Convert from BGR to RGB if needed\n",
    "    if convert_to_rgb:\n",
    "        image = image[:, :, ::-1]\n",
    "\n",
    "    # run the face detection model to find face locations\n",
    "    face_locations = face_recognition.face_locations(image)\n",
    "    # face_locations = face_recognition.face_locations(face_image, number_of_times_to_upsample=2)\n",
    "\n",
    "    # run the embedding model to get face embeddings for the supplied locations\n",
    "    face_encodings = face_recognition.face_encodings(image, face_locations, num_jitters=10)\n",
    "\n",
    "    return face_locations, face_encodings\n",
    "\n",
    "def setup_database():\n",
    "    \"\"\"\n",
    "    Load reference images and create a database of their face encodings\n",
    "    \"\"\"\n",
    "    database = {}\n",
    "    for filename in glob('training_images_face/*.jpeg'):\n",
    "        # load image\n",
    "        image_rgb = face_recognition.load_image_file(filename)\n",
    "\n",
    "        # use the name in the filename as the identity key\n",
    "        identity = os.path.splitext(os.path.basename(filename))[0]\n",
    "\n",
    "        # get the face encoding and link it to the identity\n",
    "        locations, encodings = get_face_embeddings_from_image(image_rgb)\n",
    "        database[identity] = encodings[0]\n",
    "\n",
    "    return database\n",
    "\n",
    "# identify face through image\n",
    "\n",
    "def run_face_recognition_image(database):\n",
    "    known_face_encodings = list(database.values())\n",
    "    known_face_names = list(database.keys())\n",
    "\n",
    "    img=cv2.imread('training images/chad-smith/chad3.jpeg')\n",
    "    face_locations, face_encodings=get_face_embeddings_from_image(img, convert_to_rgb=True)\n",
    "\n",
    "    for location, face_encoding in zip(face_locations, face_encodings):\n",
    "        MAX_DISTANCE=0.6\n",
    "        # get the distances from this encoding to those of all reference images\n",
    "        distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "\n",
    "        # select the closest match (smallest distance) if it's below the threshold value\n",
    "        if np.any(distances <= MAX_DISTANCE):\n",
    "            best_match_idx = np.argmin(distances)\n",
    "            name = known_face_names[best_match_idx]\n",
    "        else:\n",
    "            name = None\n",
    "    print(name)\n",
    "\n",
    "def run_face_recognition_video(database):\n",
    "    \"\"\"\n",
    "    Start the face recognition via the webcam\n",
    "    \"\"\"\n",
    "    # Open a handler for the camera\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "    # the face_recognitino library uses keys and values of your database separately\n",
    "    known_face_encodings = list(database.values())\n",
    "    known_face_names = list(database.keys())\n",
    "    \n",
    "    while video_capture.isOpened():\n",
    "        # Grab a single frame of video (and check if it went ok)\n",
    "        ok, frame = video_capture.read()\n",
    "        if not ok:\n",
    "            logging.error(\"Could not read frame from camera. Stopping video capture.\")\n",
    "            break\n",
    "#         if ok:\n",
    "           \n",
    "            \n",
    "        # run detection and embedding models\n",
    "        face_locations, face_encodings = get_face_embeddings_from_image(frame, convert_to_rgb=True)\n",
    "        MAX_DISTANCE=0.6\n",
    "        # Loop through each face in this frame of video and see if there's a match\n",
    "        for location, face_encoding in zip(face_locations, face_encodings):\n",
    "            T,R,B,L=location\n",
    "            cropped_img= frame[T:B, L:R]\n",
    "            result=real_fake(cropped_img)\n",
    "            cv2.imwrite(\"cropped.jpeg\",cropped_img) \n",
    "            # get the distances from this encoding to those of all reference images\n",
    "            if result==1:\n",
    "                distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "\n",
    "                # select the closest match (smallest distance) if it's below the threshold value\n",
    "                if np.any(distances <= MAX_DISTANCE):\n",
    "                    best_match_idx = np.argmin(distances)\n",
    "                    name = known_face_names[best_match_idx]\n",
    "                else:\n",
    "                    name = None\n",
    "\n",
    "                # put recognition info on the image\n",
    "                paint_detected_face_on_image(frame, location, name)\n",
    "            else:\n",
    "                paint_detected_face_on_image(frame, location, 'fake')\n",
    "        # Display the resulting image\n",
    "        cv2.imshow('Video', frame)\n",
    "\n",
    "        # Hit 'q' on the keyboard to quit!\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release handle to the webcam\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def paint_detected_face_on_image(frame, location, name=None):\n",
    "    \"\"\"\n",
    "    Paint a rectangle around the face and write the name\n",
    "    \"\"\"\n",
    "    # unpack the coordinates from the location tuple\n",
    "    top, right, bottom, left = location\n",
    "    \n",
    "    if name is 'fake':\n",
    "        color = (0, 0, 255)  # red for unrecognized face\n",
    "    elif name is None:\n",
    "        name = 'Unknown'\n",
    "        color = (0, 0, 255)  # red for unrecognized face\n",
    "    else:\n",
    "        color = (0, 128, 0)  # dark green for recognized face\n",
    "\n",
    "    # Draw a box around the face\n",
    "    cv2.rectangle(frame, (left, top), (right, bottom), color, 2)\n",
    "\n",
    "    # Draw a label with a name below the face\n",
    "    cv2.rectangle(frame, (left, bottom - 35), (right, bottom), color, cv2.FILLED)\n",
    "    cv2.putText(frame, name, (left + 6, bottom - 6), cv2.FONT_HERSHEY_DUPLEX, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "# run_face_recognition_image(database)\n",
    "\n",
    "# we can define accuracy  in different ways.\n",
    "\n",
    "# 1. Recognition rate\n",
    "# 2. false acceptance\n",
    "# 3. true rejections\n",
    "\n",
    "# Recognition rate is how many images correctly matching with the training images, while false acceptance is how many images (out side the dataset) are matching with the dataset images. true rejections are how many images (from the dataset) are not matching with the training dataset.\n",
    "\n",
    "def cnn4(weights_path=None):\n",
    "        model=Sequential()\n",
    "        model.add(Conv2D(kernel_size=(3,3),filters=3,input_shape=(IMG_SIZE,IMG_SIZE,3),activation=\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "        model.add(Conv2D(kernel_size=(3,3),filters=3,activation=\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "        model.add(Conv2D(kernel_size=(3,3),filters=10))\n",
    "#         model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "        model.add(Conv2D(kernel_size=(3,3),filters=10))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(1000,activation=\"sigmoid\"))\n",
    "        model.add(Dense(100,activation=\"sigmoid\"))\n",
    "        model.add(Dense(1,activation=\"sigmoid\"))\n",
    "    #     model.summary()\n",
    "        if weights_path:\n",
    "            model.load_weights(weights_path)\n",
    "        return model\n",
    "\n",
    "model = cnn4('model_cnn4.h5')\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "def real_fake(img_array):\n",
    "    new_img_array= cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n",
    "    x_test=new_img_array/255.0\n",
    "    x_test = np.expand_dims(x_test, axis=0)\n",
    "    probs= model.predict(x_test)\n",
    "    labels = (probs>0.5).astype(np.int)\n",
    "    return labels[0][0]\n",
    "\n",
    "database = setup_database()\n",
    "run_face_recognition_video(database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
